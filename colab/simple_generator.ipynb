{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled24.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9b23f0df6b8447e48dafeef3bfdd98fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_637ec635ba614ac58f3046e51816dfc9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_79aa5d2d7ac34a63ae1ef911b0c3fa4a",
              "IPY_MODEL_69cf9c4382c84031acd72dcecfabf821"
            ]
          }
        },
        "637ec635ba614ac58f3046e51816dfc9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "79aa5d2d7ac34a63ae1ef911b0c3fa4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_22a99a5add1f489e9d100eb53849e1a2",
            "_dom_classes": [],
            "description": "  1%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 625,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 9,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3046eaeecef84f73b8d272d6256d09f7"
          }
        },
        "69cf9c4382c84031acd72dcecfabf821": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_678cadba689a4818ab8a2089ac2ffe91",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 9/625 [00:07&lt;06:45,  1.52it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_821b5c3caa034328bd2c57d66bddd87a"
          }
        },
        "22a99a5add1f489e9d100eb53849e1a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3046eaeecef84f73b8d272d6256d09f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "678cadba689a4818ab8a2089ac2ffe91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "821b5c3caa034328bd2c57d66bddd87a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jm0iV6OKIjG0",
        "outputId": "07d5d0ce-0409-4ea4-963b-f9a202689c89"
      },
      "source": [
        "!pip install fastai --upgrade"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fastai\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e8/79/e8a87e4c20238e114671314426227db8647d2b42744eab79e0917c59865e/fastai-2.3.1-py3-none-any.whl (194kB)\n",
            "\r\u001b[K     |█▊                              | 10kB 22.2MB/s eta 0:00:01\r\u001b[K     |███▍                            | 20kB 28.8MB/s eta 0:00:01\r\u001b[K     |█████                           | 30kB 32.7MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 40kB 35.9MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 51kB 38.6MB/s eta 0:00:01\r\u001b[K     |██████████                      | 61kB 40.2MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 71kB 35.2MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 81kB 29.4MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 92kB 30.7MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 102kB 30.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 112kB 30.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 122kB 30.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 133kB 30.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 143kB 30.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 153kB 30.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 163kB 30.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 174kB 30.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 184kB 30.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 194kB 30.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 204kB 30.4MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: torchvision>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from fastai) (0.9.1+cu101)\n",
            "Requirement already satisfied, skipping upgrade: spacy<4 in /usr/local/lib/python3.7/dist-packages (from fastai) (2.2.4)\n",
            "Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.7/dist-packages (from fastai) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/dist-packages (from fastai) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: pip in /usr/local/lib/python3.7/dist-packages (from fastai) (19.3.1)\n",
            "Requirement already satisfied, skipping upgrade: pillow>6.0.0 in /usr/local/lib/python3.7/dist-packages (from fastai) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: fastprogress>=0.2.4 in /usr/local/lib/python3.7/dist-packages (from fastai) (1.0.0)\n",
            "Collecting fastcore<1.4,>=1.3.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/b0/f1fbf554e0bf3c76e1bdc3b82eedfe41fcf656479586be38c64421082b1b/fastcore-1.3.20-py3-none-any.whl (53kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 6.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: pandas in /usr/local/lib/python3.7/dist-packages (from fastai) (1.1.5)\n",
            "Requirement already satisfied, skipping upgrade: torch<1.9,>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from fastai) (1.8.1+cu101)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.7/dist-packages (from fastai) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.7/dist-packages (from fastai) (20.9)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.7/dist-packages (from fastai) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib in /usr/local/lib/python3.7/dist-packages (from fastai) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.8.2->fastai) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (7.4.0)\n",
            "Requirement already satisfied, skipping upgrade: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (2.0.5)\n",
            "Requirement already satisfied, skipping upgrade: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (0.8.2)\n",
            "Requirement already satisfied, skipping upgrade: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (1.1.3)\n",
            "Requirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (3.0.5)\n",
            "Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (1.0.5)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (56.1.0)\n",
            "Requirement already satisfied, skipping upgrade: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (1.0.5)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fastai) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fastai) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fastai) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fastai) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->fastai) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->fastai) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<1.9,>=1.7.0->fastai) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->fastai) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->fastai) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai) (1.3.1)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<4->fastai) (3.10.1)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->fastai) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<4->fastai) (3.4.1)\n",
            "Installing collected packages: fastcore, fastai\n",
            "  Found existing installation: fastai 1.0.61\n",
            "    Uninstalling fastai-1.0.61:\n",
            "      Successfully uninstalled fastai-1.0.61\n",
            "Successfully installed fastai-2.3.1 fastcore-1.3.20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syTHA5HgImfd"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from tqdm.notebook import tqdm\n",
        "from skimage.color import rgb2lab, lab2rgb\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torchvision import transforms\n",
        "from torchvision.models.resnet import resnet18\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from fastai.vision.learner import create_body\n",
        "from fastai.vision.models.unet import DynamicUnet\n",
        "from fastai.data.external import untar_data, URLs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhRbLMRtIot-"
      },
      "source": [
        "SIZE = 256"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ey7XgzDpIq2v"
      },
      "source": [
        "class TrainingDataset(Dataset):\n",
        "  def __init__(self, paths):\n",
        "    self.transforms = transforms.Compose([\n",
        "            transforms.Resize((SIZE, SIZE)),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "        ])\n",
        "    self.paths = paths\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    img = Image.open(self.paths[idx]).convert(\"RGB\")\n",
        "    img = self.transforms(img)\n",
        "    img = np.array(img)\n",
        "\n",
        "    lab_img = rgb2lab(img).astype(\"float32\")\n",
        "    lab_img = transforms.ToTensor()(lab_img)\n",
        "\n",
        "    L = lab_img[[0], ...] / 50. - 1.\n",
        "    ab = lab_img[[1, 2], ...] / 110.\n",
        "\n",
        "    return {\"L\": L, \"ab\": ab}\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.paths)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onfMDFi1IsmR"
      },
      "source": [
        "class ValidationDataset(Dataset):\n",
        "  def __init__(self, paths):\n",
        "    self.transforms = transforms.Compose([\n",
        "            transforms.Resize((SIZE, SIZE)),\n",
        "        ])\n",
        "    self.paths = paths\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    img = Image.open(self.paths[idx]).convert(\"RGB\")\n",
        "    img = self.transforms(img)\n",
        "    img = np.array(img)\n",
        "\n",
        "    lab_img = rgb2lab(img).astype(\"float32\")\n",
        "    lab_img = transforms.ToTensor()(lab_img)\n",
        "\n",
        "    L = lab_img[[0], ...] / 50. - 1.\n",
        "    ab = lab_img[[1, 2], ...] / 110.\n",
        "\n",
        "    return {\"L\": L, \"ab\": ab}\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.paths)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_ZuJzAQIujq"
      },
      "source": [
        "class CNNBlock(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, stride):\n",
        "    super().__init__()\n",
        "\n",
        "    self.conv = nn.Sequential(\n",
        "      nn.Conv2d(\n",
        "          in_channels, out_channels, 4, stride, 1, bias=False, padding_mode=\"reflect\"\n",
        "      ),\n",
        "      nn.BatchNorm2d(out_channels),\n",
        "      nn.LeakyReLU(0.2),\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.conv(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjHPuM0kIwh6"
      },
      "source": [
        "class PatchDiscriminator(nn.Module):\n",
        "  def __init__(self, x_channels, y_channels, features=[64, 128, 256, 512]):\n",
        "    super().__init__()\n",
        "\n",
        "    self.initial = nn.Sequential(\n",
        "      nn.Conv2d(x_channels + y_channels, features[0], 4, 2, 1, padding_mode=\"reflect\"),\n",
        "      nn.LeakyReLU(0.2),\n",
        "    )\n",
        "\n",
        "    layers = []\n",
        "    for i in range(1, len(features)):\n",
        "      layers.append(\n",
        "        CNNBlock(features[i-1], features[i], 1 if features[i] == features[-1] else 2),\n",
        "      )\n",
        "\n",
        "    layers.append(\n",
        "      nn.Conv2d(features[-1], 1, 4, 1, 1, padding_mode=\"reflect\"),\n",
        "    )\n",
        "\n",
        "    self.model = nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, xy):\n",
        "    xy = self.initial(xy)\n",
        "\n",
        "    return self.model(xy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FK0iUtzIyqM"
      },
      "source": [
        "class GANLoss(nn.Module):\n",
        "  def __init__(self, real_label=1., fake_label=0.):\n",
        "    super().__init__()\n",
        "\n",
        "    self.register_buffer(\"real_label\", torch.tensor(real_label))\n",
        "    self.register_buffer(\"fake_label\", torch.tensor(fake_label))\n",
        "\n",
        "    self.loss = nn.BCEWithLogitsLoss()\n",
        "\n",
        "  def get_labels(self, preds, target_is_real):\n",
        "    if target_is_real:\n",
        "      return self.real_label.expand_as(preds)\n",
        "\n",
        "    return self.fake_label.expand_as(preds)\n",
        "\n",
        "  def __call__(self, preds, target_is_real):\n",
        "    labels = self.get_labels(preds, target_is_real)\n",
        "\n",
        "    return self.loss(preds, labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbUtEASzI0-U"
      },
      "source": [
        "class MainModel(nn.Module):\n",
        "  def __init__(self, device, D, G, lr_G=2e-4, lr_D=2e-4, beta1=.5, beta2=.999, lambda_L1=100.):\n",
        "    super().__init__()\n",
        "\n",
        "    self.device = device\n",
        "\n",
        "    self.D = D\n",
        "    self.G = G\n",
        "\n",
        "    self.GANcriterion = GANLoss().to(self.device)\n",
        "    self.L1criterion = nn.L1Loss()\n",
        "\n",
        "    self.opt_G = optim.Adam(self.G.parameters(), lr=lr_G, betas=(beta1, beta2))\n",
        "    self.opt_D = optim.Adam(self.D.parameters(), lr=lr_D, betas=(beta1, beta2))\n",
        "\n",
        "    self.lambda_L1 = lambda_L1\n",
        "\n",
        "  def set_requires_grad(self, model, requires_grad):\n",
        "    for parameter in model.parameters():\n",
        "      parameter.requires_grad = requires_grad\n",
        "\n",
        "  def setup_input(self, data):\n",
        "    self.L = data[\"L\"].to(self.device)\n",
        "    self.ab = data[\"ab\"].to(self.device)\n",
        "\n",
        "  def forward(self):\n",
        "    self.fake_color = self.G(self.L).to(device)\n",
        "\n",
        "  def backward_D(self):\n",
        "    fake_image = torch.cat([self.L, self.fake_color], dim=1)\n",
        "    fake_preds = self.D(fake_image.detach())\n",
        "\n",
        "    self.loss_D_fake = self.GANcriterion(fake_preds, False)\n",
        "\n",
        "    real_image = torch.cat([self.L, self.ab], dim=1)\n",
        "    real_preds = self.D(real_image)\n",
        "\n",
        "    self.loss_D_real = self.GANcriterion(real_preds, True)\n",
        "\n",
        "    self.loss_D = (self.loss_D_fake + self.loss_D_real) * .5\n",
        "\n",
        "    self.loss_D.backward()\n",
        "\n",
        "  def backward_G(self):\n",
        "    fake_image = torch.cat([self.L, self.fake_color], dim=1)\n",
        "    fake_preds = self.D(fake_image)\n",
        "\n",
        "    self.loss_G_GAN = self.GANcriterion(fake_preds, True)\n",
        "    self.loss_G_L1 = self.lambda_L1 * self.L1criterion(self.fake_color, self.ab)\n",
        "\n",
        "    self.loss_G = self.loss_G_GAN + self.loss_G_L1\n",
        "\n",
        "    self.loss_G.backward()\n",
        "\n",
        "  def optimize(self):\n",
        "    self.forward()\n",
        "\n",
        "    self.D.train()\n",
        "    self.set_requires_grad(self.D, True)\n",
        "    self.opt_D.zero_grad()\n",
        "    self.backward_D()\n",
        "    self.opt_D.step()\n",
        "\n",
        "    self.G.train()\n",
        "    self.set_requires_grad(self.D, False)\n",
        "    self.opt_G.zero_grad()\n",
        "    self.backward_G()\n",
        "    self.opt_G.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04oT3qP9I5v5"
      },
      "source": [
        "class AverageMeter:\n",
        "  def __init__(self):\n",
        "    self.reset()\n",
        "\n",
        "  def reset(self):\n",
        "    self.count, self.avg, self.sum = 0., 0., 0.\n",
        "\n",
        "  def update(self, val, count):\n",
        "    self.count += count\n",
        "    self.sum += val * count\n",
        "    self.avg = self.sum / self.count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZRCHUQuI7sp"
      },
      "source": [
        "def init_loss_meters():\n",
        "  loss_D_fake = AverageMeter()\n",
        "  loss_D_real = AverageMeter()\n",
        "  loss_D = AverageMeter()\n",
        "\n",
        "  loss_G_GAN = AverageMeter()\n",
        "  loss_G_L1 = AverageMeter()\n",
        "  loss_G = AverageMeter()\n",
        "\n",
        "  return {\"loss_D_fake\": loss_D_fake,\n",
        "          \"loss_D_real\": loss_D_real,\n",
        "          \"loss_D\": loss_D,\n",
        "          \"loss_G_GAN\": loss_G_GAN,\n",
        "          \"loss_G_L1\": loss_G_L1,\n",
        "          \"loss_G\": loss_G}\n",
        "\n",
        "def update_losses(model, loss_meters, count):\n",
        "  for loss_name, loss_meter in loss_meters.items():\n",
        "    loss = getattr(model, loss_name)\n",
        "    loss_meter.update(loss.item(), count)\n",
        "\n",
        "def log_results(loss_meters):\n",
        "  for loss_name, loss_meter in loss_meters.items():\n",
        "    print(f\"{loss_name}: {loss_meter.avg:.4f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sm4ZagQJAIk"
      },
      "source": [
        "def lab_to_rgb(L, ab):\n",
        "  L = (L + 1.) * 50.\n",
        "  ab = ab * 110.\n",
        "\n",
        "  Lab = torch.cat([L, ab], dim=1).permute(0, 2, 3, 1).cpu().numpy()\n",
        "\n",
        "  rgb_imgs = []\n",
        "  for img in Lab:\n",
        "    img_rgb = lab2rgb(img)\n",
        "    rgb_imgs.append(img_rgb)\n",
        "\n",
        "  return np.stack(rgb_imgs, axis=0)\n",
        "\n",
        "def visualize(model, data, lead, save=True):\n",
        "  model.G.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    model.setup_input(data)\n",
        "    model.forward()\n",
        "\n",
        "  model.G.train()\n",
        "\n",
        "  fake_color = model.fake_color.detach()\n",
        "  real_color = model.ab\n",
        "  L = model.L\n",
        "\n",
        "  fake_imgs = lab_to_rgb(L, fake_color)\n",
        "  real_imgs = lab_to_rgb(L, real_color)\n",
        "\n",
        "  fig = plt.figure(figsize=(15, 8))\n",
        "  for i in range(5):\n",
        "    ax = plt.subplot(3, 5, i + 1)\n",
        "    ax.imshow(L[i][0].cpu(), cmap=\"gray\")\n",
        "    ax.axis(\"off\")\n",
        "    ax = plt.subplot(3, 5, i + 1 + 5)\n",
        "    ax.imshow(fake_imgs[i])\n",
        "    ax.axis(\"off\")\n",
        "    ax = plt.subplot(3, 5, i + 1 + 10)\n",
        "    ax.imshow(real_imgs[i])\n",
        "    ax.axis(\"off\")\n",
        "  plt.show()\n",
        "\n",
        "  if save:\n",
        "    fig.savefig(f\"./images/colorization_{lead}_{time.time()}.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gZyJp59JE1t"
      },
      "source": [
        "class Block(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, down=True, act=\"relu\", use_dropout=False):\n",
        "    super(Block, self).__init__()\n",
        "\n",
        "    self.conv = nn.Sequential(\n",
        "      nn.Conv2d(in_channels, out_channels, 4, 2, 1, bias=False, padding_mode=\"reflect\")\n",
        "      if down\n",
        "      else nn.ConvTranspose2d(in_channels, out_channels, 4, 2, 1, bias=False),\n",
        "      nn.BatchNorm2d(out_channels),\n",
        "      nn.ReLU() if act == \"relu\" else nn.LeakyReLU(0.2),\n",
        "    )\n",
        "\n",
        "    self.use_dropout = use_dropout\n",
        "    self.dropout = nn.Dropout(0.5)\n",
        "    self.down = down\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv(x)\n",
        "\n",
        "    return self.dropout(x) if self.use_dropout else x\n",
        "\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self, in_channels=1, out_channels=2, features=64):\n",
        "    super().__init__()\n",
        "\n",
        "    self.initial_down = nn.Sequential(\n",
        "      nn.Conv2d(in_channels, features, 4, 2, 1, padding_mode=\"reflect\"),\n",
        "      nn.LeakyReLU(0.2),\n",
        "    )\n",
        "    self.down1 = Block(features, features * 2, True, \"leaky\", False)\n",
        "    self.down2 = Block(features * 2, features * 4, True, \"leaky\", False)\n",
        "    self.down3 = Block(features * 4, features * 8, True, \"leaky\", False)\n",
        "    self.down4 = Block(features * 8, features * 8, True, \"leaky\", False)\n",
        "    self.down5 = Block(features * 8, features * 8, True, \"leaky\", False)\n",
        "    self.down6 = Block(features * 8, features * 8, True, \"leaky\", False)\n",
        "    self.bottleneck = nn.Sequential(nn.Conv2d(features * 8, features * 8, 4, 2, 1), nn.ReLU())\n",
        "\n",
        "    self.up1 = Block(features * 8, features * 8, False, act=\"relu\", use_dropout=True)\n",
        "    self.up2 = Block(features * 8 * 2, features * 8, False, \"relu\", True)\n",
        "    self.up3 = Block(features * 8 * 2, features * 8, False, \"relu\", True)\n",
        "    self.up4 = Block(features * 8 * 2, features * 8, False, \"relu\", False)\n",
        "    self.up5 = Block(features * 8 * 2, features * 4, False, \"relu\", False)\n",
        "    self.up6 = Block(features * 4 * 2, features * 2, False, \"relu\", False)\n",
        "    self.up7 = Block(features * 2 * 2, features, False, \"relu\", False)\n",
        "    self.final_up = nn.Sequential(\n",
        "      nn.ConvTranspose2d(features * 2, out_channels, 4, 2, 1),\n",
        "      nn.Tanh(),\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    d1 = self.initial_down(x)\n",
        "    d2 = self.down1(d1)\n",
        "    d3 = self.down2(d2)\n",
        "    d4 = self.down3(d3)\n",
        "    d5 = self.down4(d4)\n",
        "    d6 = self.down5(d5)\n",
        "    d7 = self.down6(d6)\n",
        "    bottleneck = self.bottleneck(d7)\n",
        "\n",
        "    up1 = self.up1(bottleneck)\n",
        "    up2 = self.up2(torch.cat([up1, d7], 1))\n",
        "    up3 = self.up3(torch.cat([up2, d6], 1))\n",
        "    up4 = self.up4(torch.cat([up3, d5], 1))\n",
        "    up5 = self.up5(torch.cat([up4, d4], 1))\n",
        "    up6 = self.up6(torch.cat([up5, d3], 1))\n",
        "    up7 = self.up7(torch.cat([up6, d2], 1))\n",
        "\n",
        "    return self.final_up(torch.cat([up7, d1], 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "PZ1GoCJgJKsF",
        "outputId": "0a30d84c-d18c-49c3-c1ac-a114c9ac5c5e"
      },
      "source": [
        "root = str(untar_data(URLs.COCO_SAMPLE)) + \"/train_sample\"\n",
        "\n",
        "paths = glob.glob(root + \"/*.jpg\")\n",
        "\n",
        "np.random.seed(42)\n",
        "paths_subset = np.random.choice(paths, 12_000, replace=False)\n",
        "\n",
        "rand_idxs = np.random.permutation(12_000)\n",
        "train_idxs = rand_idxs[:10_000]\n",
        "val_idxs = rand_idxs[10_000:]\n",
        "\n",
        "train_paths = paths_subset[train_idxs]\n",
        "val_paths = paths_subset[val_idxs]\n",
        "\n",
        "train_dset = TrainingDataset(train_paths)\n",
        "val_dset = ValidationDataset(val_paths)\n",
        "\n",
        "train_dl = DataLoader(train_dset, 16, num_workers=2, pin_memory=True)\n",
        "val_dl = DataLoader(val_dset, 16, num_workers=2, pin_memory=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzPIYv8HJNUp"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLDN6EL1JO9b"
      },
      "source": [
        "D = PatchDiscriminator(1, 2).to(device)\n",
        "G = Generator().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ym7uRcICJW04"
      },
      "source": [
        "model = MainModel(device, D, G)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McixLLi8JY2D"
      },
      "source": [
        "def train_model(model, train_dl, val_dl, epochs, display_every=200):\n",
        "  fixed_val_data = next(iter(val_dl))\n",
        "\n",
        "  for e in range(epochs):\n",
        "    loss_meters = init_loss_meters()\n",
        "    i = 0\n",
        "    for data in tqdm(train_dl):\n",
        "      model.setup_input(data)\n",
        "\n",
        "      model.optimize()\n",
        "\n",
        "      update_losses(model, loss_meters, data[\"L\"].size(0))\n",
        "\n",
        "      i += 1\n",
        "      if i % display_every == 0:\n",
        "        print(f\"\\nEpoch {e+1}/{epochs}\")\n",
        "        print(f\"Iteration {i}/{len(train_dl)}\")\n",
        "        log_results(loss_meters)\n",
        "\n",
        "        visualize(model, fixed_val_data, e)\n",
        "\n",
        "    torch.save(model.D.state_dict(), f\"./models/{e}_D_{time.time()}.pt\")\n",
        "    torch.save(model.G.state_dict(), f\"./models/{e}_G_{time.time()}.pt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359,
          "referenced_widgets": [
            "9b23f0df6b8447e48dafeef3bfdd98fe",
            "637ec635ba614ac58f3046e51816dfc9",
            "79aa5d2d7ac34a63ae1ef911b0c3fa4a",
            "69cf9c4382c84031acd72dcecfabf821",
            "22a99a5add1f489e9d100eb53849e1a2",
            "3046eaeecef84f73b8d272d6256d09f7",
            "678cadba689a4818ab8a2089ac2ffe91",
            "821b5c3caa034328bd2c57d66bddd87a"
          ]
        },
        "id": "PLMV-u2zJbpB",
        "outputId": "f07a67c9-b553-4a86-9a0b-9b11db7c973c"
      },
      "source": [
        "train_model(model, train_dl, val_dl, 100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9b23f0df6b8447e48dafeef3bfdd98fe",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=625.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-456df6a4010f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-18-ee2be7b71e26>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_dl, val_dl, epochs, display_every)\u001b[0m\n\u001b[1;32m     10\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m       \u001b[0mupdate_losses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_meters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"L\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m       \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-d105ea8a4ce0>\u001b[0m in \u001b[0;36mupdate_losses\u001b[0;34m(model, loss_meters, count)\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mloss_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_meter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloss_meters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mloss_meter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlog_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_meters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}